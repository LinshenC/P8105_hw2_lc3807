p8105_hw2_lc3807
================
Linshen Cai
2023-10-04

## problem 0

``` r
library(tidyverse)
library(readxl)
```

## problem 1

``` r
# creat dataframe of month
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

#import data frame and clean it as follow
pols = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

First, clean the data in pols-month.csv, which shows how many national
politicians are now affiliated with either the Democratic Party or the
Republican Party. There are several instances where `prez_gop` equals
`2`; these are the months in which Ford took office after Nixon
resigned. We code these as `gop` (the same as values when `prez_gop` is
`1`) in the new `president` variable established as part of our data
cleansing.

``` r
snp = 
  read_csv(
    "./data/fivethirtyeight_datasets/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```

Second, we also clean the 538 `snp` data, which contains information
related to Standard & Poor’s stock market index.

``` r
unemployment = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Finally, we tidy the `unemployment` data so that it can be merged with
the previous datasets.

``` r
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
## tibble [822 × 13] (S3: tbl_df/tbl/data.frame)
##  $ year        : num [1:822] 1947 1947 1947 1947 1947 ...
##  $ month       : chr [1:822] "January" "February" "March" "April" ...
##  $ month_num   : int [1:822] 1 2 3 4 5 6 7 8 9 10 ...
##  $ gov_gop     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
##  $ sen_gop     : num [1:822] 51 51 51 51 51 51 51 51 51 51 ...
##  $ rep_gop     : num [1:822] 253 253 253 253 253 253 253 253 253 253 ...
##  $ gov_dem     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
##  $ sen_dem     : num [1:822] 45 45 45 45 45 45 45 45 45 45 ...
##  $ rep_dem     : num [1:822] 198 198 198 198 198 198 198 198 198 198 ...
##  $ president   : chr [1:822] "dem" "dem" "dem" "dem" ...
##  $ month_abb   : chr [1:822] "Jan" "Feb" "Mar" "Apr" ...
##  $ close       : num [1:822] NA NA NA NA NA NA NA NA NA NA ...
##  $ unemployment: num [1:822] NA NA NA NA NA NA NA NA NA NA ...
```

We merge the three datasets!

The ‘pols’ data contains 822 observations and 11 variables, and it
provides information on the distribution of party identification
(Democrat or Republican) among governors and senators for a certain year
from years.The`snp`data consists of 787 observations and 3 variables,
which range from years to months.The `unemployment` data includes 816
observations and 3 variables with a range of years.

## Problem 2

First, I import Mr.Trash Wheel sheet from excel and omit non-data
entries

``` r

#import dataframe use read_excel

mr_trash_wheel_df = 
  read_excel(path = "./data/202309 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel",
             range = "A2:N586",
             na = c("", "NA", "N/A")
             ) |> 
  janitor::clean_names() |> 
  
  #re-calculate homes powered
  
  mutate(homes_powered = weight_tons * 500 / 30, 
         trash_wheel_type = "Mr. Trash Wheel",
         year = as.double(year)
         )|> 
  select(trash_wheel_type, everything())
```

Second, I import Professor Trash Wheel sheet from excel and omit
non-data entries.

``` r

#import dataframe use read_excel
prof_trash_df = 
  read_excel(
    "./data/202309 Trash Wheel Collection Data.xlsx",
    sheet = "Professor Trash Wheel",
    range = "A2:M108",
    na = c("", "NA", "N/A")
    ) |> 
  janitor::clean_names() |> 
  
#re-calculate homes powered
  mutate(
    homes_powered = weight_tons * 500 / 30,
    trash_wheel_type = "Professor Trash Wheel"
    ) |> 
  select(trash_wheel_type, everything())
  
```

Third, I import Gwynnda Trash Wheel sheet from excel and omit non-data
entries.

``` r

#import dataframe use read_excel
gwynnda_trash_df = 
  read_excel(
    "./data/202309 Trash Wheel Collection Data.xlsx",
    sheet = "Gwynnda Trash Wheel",
    range = "A2:L157",
    na = c("", "NA", "N/A")
    ) |> 
  janitor::clean_names() |> 
  
#re-calculate homes powered
  mutate(
    homes_powered = weight_tons * 500 / 30,
    trash_wheel_type = "Gwynnda Trash Wheel"
    ) |> 
  select(trash_wheel_type, everything())
```

Finally, we merge all three dateframes above and calculate total weight
of trash collected by Professor Trash Wheel and the total number of
cigarette butts collected by Gwynnda in July of 2021.

``` r
# merge all three dataframes 
data_all = bind_rows(mr_trash_wheel_df, prof_trash_df, gwynnda_trash_df) 

# calculate total weight of trash collected by Professor Trash Wheel
total_prof_trash_weight = data_all |> 
  filter(trash_wheel_type == "Professor Trash Wheel") |> 
  pull(weight_tons) |> 
  sum()
total_prof_trash_weight
## [1] 216.26

# calculate total number of cigarette butts collected by Gwynnda in July of 2021
total_gwynnda_cigarette_butts_july = data_all |> 
  filter(trash_wheel_type == "Gwynnda Trash Wheel" & month == "July" & year == 2021) |> 
  pull(cigarette_butts) |> 
  sum()
total_gwynnda_cigarette_butts_july
## [1] 16300
```

The `mr_trash_wheel_df` data has 584 observations and 15 variables and
tells us about how many tons of garbage Mr trash wheel collects and what
types of garbage are included(each variables) for a given year from
years 2014 to 2023. The `prof_trash_df` data has 106 observations and 14
variables, ranging from years 2017 to 2023. The `gwynnda_trash_df` data
has 155 observations and 13 variables ranging from years 2021 to 2023.
After we combine three sheets, the `data_all` date fame has845
observations and 15 variables and contains all information about trash
collected from these three different trash wheels for a given year from
2014 to 2023. The total weight of trash collected by Professor Trash
Wheel are 216.26 and the total number of cigarette butts collected by
Gwynnda in July of 2021 are1.63^{4}.

## Problem 3

First,import, clean, and tidy the dataset of baseline demographics and
remove any participants who do not meet the stated inclusion criteria.

``` r
# load the dataset
mci_baseline_df = 
  read_csv("./data/data_mci/MCI_baseline.csv", 
           skip = 1) |>
  
#clean data
  janitor::clean_names() |> 
  
#encode sex and APOE4 carrier status
  mutate(
    sex = ifelse(sex == 1, "male", "female"),
    apoe4 = ifelse(apoe4 == 1, "carrier", "non-carrier" )
         ) 

# remove the participants who don't meet the stated inclusion criteria
mci_at_baseline_df = mci_baseline_df |>
  mutate(age_at_onset = ifelse(age_at_onset == '.', NA, age_at_onset)) |> 
  filter(current_age < age_at_onset | is.na(age_at_onset))



# calculate for the average baseline age
base_mean_age_mci = mean(pull(mci_at_baseline_df, current_age))

#calculate the proportion
n_carrier_female = mci_at_baseline_df |> 
  filter(sex == 'female') |> 
  filter(apoe4 == 'carrier') |> 
  count()

n_female = mci_baseline_df |> 
  filter(sex == 'female') |> 
  count()

proportion = n_carrier_female/n_female
```

The first row must be skipped throughout the import procedure because
our dataset does not require remarks.Based on notes, Sex == 0 represents
the participant is female. apoe4 == 0 represents the participant is
non-carrier. Then we use mutate funtion to ensure that sex and APOE4
carrier status are appropriate encoded (i.e. not numeric) according to
notes. We also use filter function to remove any participants who do not
meet the stated inclusion criteria. It means you need to remove any N/A
value in variable `age at onset` variable by using filter function.
There are 483 participants were recruited, 479 develop MCI. The average
baseline age is 65.0286013. The proportion of women in the study are
APOE4 carriers is 0.2985782.

First, Import, clean, and tidy the dataset of longitudinally observed
biomarker values.

``` r
# load the amyloid dataset
mci_amyloid_df = read.csv('./data/data_mci/mci_amyloid.csv', skip = 1) |> 
  janitor::clean_names()

mci_amyloid_df = mci_amyloid_df |> 
  rename(id = study_id,
         second_year = time_2,
         fourth_year = time_4,
         sixth_year = time_6,
         eighth_year = time_8) |> 
  pivot_longer(
    baseline:eighth_year,
    names_to = "time",
    values_to = "value"
    )
```

We still don’t require notes in this dataset, so we skip the first row.
The study_id and time variables are changed to id and years. To make the
dataset easier to understand by clearly displaying time and value, we
use pivot_longer() function. The dateset has some NA values, which
indicates that certain ratio values are missing. There are 2435
observations and 3 variables. The dateframe contains important variables
like id, year, and value once the dataset has been cleaned and
organized.

Second, check whether some participants appear in only the baseline or
amyloid datasets and combine the demographic and biomarker datasets so
that only participants who appear in both datasets are retained.

``` r
#Check participants appearing in only baseline or amyloid datasets
unique_baseline_participants = anti_join(mci_at_baseline_df, mci_amyloid_df,by = "id")

unique_amyloid_participants = anti_join(mci_amyloid_df, mci_at_baseline_df, by = "id")

only_baseline_id = mci_at_baseline_df |> 
  pull(id) |> 
  setdiff(mci_amyloid_df |> pull(id))

only_amyloid_id = mci_amyloid_df |> 
  pull(id) |> 
  setdiff(mci_at_baseline_df |> pull(id))

# combine two datasets together
combined_dataframe = inner_join(mci_at_baseline_df, mci_amyloid_df, by = "id")
```

Only participants with the id 14, 49, 92, 179, 268, 304, 389, 412 exist
in the baseline dataset, totaling 8.Only participants with the id 72,
234, 283, 380, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,
495 present in the amyloid dataset, totaling 16. There are 471
participants present in both datasets; each participant has 5 rows of
data (baseline to 8th year), hence there are 2355 rows total in the
combined dataset. The variables are 8.

``` r
# export the result as a CSV to your data directory
write.csv(combined_dataframe, file = "./data/data_mci/combined_dataframe.csv", row.names = T)
```
