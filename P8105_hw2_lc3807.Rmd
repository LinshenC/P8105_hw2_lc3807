---
title: "p8105_hw2_lc3807"
author: "Linshen Cai"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

## problem 0

```{r library}
library(tidyverse)
library(readxl)
```


## problem 1

```{r}
# creat dataframe of month
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

#import data frame and clean it as follow
pols = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

First, clean the data in pols-month.csv, which shows how many national politicians are now affiliated with either the Democratic Party or the Republican Party. There are several instances where `prez_gop` equals `2`; these are the months in which Ford took office after Nixon resigned. We code these as `gop` (the same as values when `prez_gop` is `1`) in the new `president` variable established as part of our data cleansing.

```{r clean_538_snp}
snp = 
  read_csv(
    "./data/fivethirtyeight_datasets/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```

Second, we also clean the 538 `snp` data, which contains information related to Standard & Poorâ€™s stock market index.

```{r clean_538_unemp}
unemployment = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Finally, we tidy the `unemployment` data so that it can be merged with the previous datasets.

```{r merge_538}
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

We merge the three datasets!

The 'pols' data contains `r nrow(pols)` observations and `r ncol(pols)` variables, and it provides information on the distribution of party identification (Democrat or Republican) among governors and senators for a certain year from years.The`snp`data consists of `r nrow(snp)` observations and `r ncol(snp)` variables, which range from years to months.The `unemployment` data includes `r nrow(unemployment)` observations and `r ncol(unemployment)` variables with a range of years.

## Problem 2

First, I import Mr.Trash Wheel sheet from excel and omit non-data entries

```{r clean Mr.Trash Wheel dataset}

#import dataframe use read_excel

mr_trash_wheel_df = 
  read_excel(path = "./data/202309 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel",
             range = "A2:N586",
             na = c("", "NA", "N/A")
             ) |> 
  janitor::clean_names() |> 
  
  #re-calculate homes powered
  
  mutate(homes_powered = weight_tons * 500 / 30, 
         trash_wheel_type = "Mr. Trash Wheel",
         year = as.double(year)
         )|> 
  select(trash_wheel_type, everything())

mr_trash_wheel_df
```
Second, I import Professor Trash Wheel sheet from excel and omit non-data entries.

```{r clean Professor Trash Wheel dataset}

#import dataframe use read_excel
prof_trash_df = 
  read_excel(
    "./data/202309 Trash Wheel Collection Data.xlsx",
    sheet = "Professor Trash Wheel",
    range = "A2:M108",
    na = c("", "NA", "N/A")
    ) |> 
  janitor::clean_names() |> 
  
#re-calculate homes powered
  mutate(
    homes_powered = weight_tons * 500 / 30,
    trash_wheel_type = "Professor Trash Wheel"
    ) |> 
  select(trash_wheel_type, everything())
  
prof_trash_df
```

Third, I import Gwynnda Trash Wheel sheet from excel and omit non-data entries.

```{r clean Gwynnda Trash Wheel dataset}

#import dataframe use read_excel
gwynnda_trash_df = 
  read_excel(
    "./data/202309 Trash Wheel Collection Data.xlsx",
    sheet = "Gwynnda Trash Wheel",
    range = "A2:L157",
    na = c("", "NA", "N/A")
    ) |> 
  janitor::clean_names() |> 
  
#re-calculate homes powered
  mutate(
    homes_powered = weight_tons * 500 / 30,
    trash_wheel_type = "Gwynnda Trash Wheel"
    ) |> 
  select(trash_wheel_type, everything())

gwynnda_trash_df
```

Finally, we merge all three dateframes above and calculate total weight of trash collected by Professor Trash Wheel and the total number of cigarette butts collected by Gwynnda in July of 2021.

```{r combine three sheets}
# merge all three dataframes 
data_all = bind_rows(mr_trash_wheel_df, prof_trash_df, gwynnda_trash_df) 

data_all

# calculate total weight of trash collected by Professor Trash Wheel
total_prof_trash_weight = data_all |> 
  filter(trash_wheel_type == "Professor Trash Wheel") |> 
  pull(weight_tons) |> 
  sum()
total_prof_trash_weight

# calculate total number of cigarette butts collected by Gwynnda in July of 2021
total_gwynnda_cigarette_butts_july = data_all |> 
  filter(trash_wheel_type == "Gwynnda Trash Wheel" & month == "July" & year == 2021) |> 
  pull(cigarette_butts) |> 
  sum()
total_gwynnda_cigarette_butts_july

```

The `mr_trash_wheel_df` data has `r nrow(mr_trash_wheel_df)` observations and `r ncol(mr_trash_wheel_df)` variables and tells us about how many tons of garbage Mr trash wheel collects and what types of garbage are included(each variables) for a given year from years `r mr_trash_wheel_df |> pull(year) |> min()` to `r mr_trash_wheel_df |> pull(year) |> max()`. The `prof_trash_df` data has `r nrow(prof_trash_df)` observations and `r ncol(prof_trash_df)` variables, ranging from years `r prof_trash_df |> pull(year) |> min()` to `r prof_trash_df |> pull(year) |> max()`. The `gwynnda_trash_df` data has `r nrow(gwynnda_trash_df)` observations and `r ncol(gwynnda_trash_df)` variables ranging from years `r gwynnda_trash_df |> pull(year) |> min()` to `r gwynnda_trash_df |> pull(year) |> max()`. After we combine three sheets, the `data_all` date fame has`r nrow(data_all)` observations and `r ncol(data_all)` variables and contains all information about trash collected from these three different trash wheels for a given year from `r data_all |> pull(year) |> min()` to `r data_all |> pull(year) |> max()`. The total weight of trash collected by Professor Trash Wheel are `r total_prof_trash_weight` and the total number of cigarette butts collected by Gwynnda in July of 2021 are`r total_gwynnda_cigarette_butts_july`.


## Problem 3

First,import, clean, and tidy the dataset of baseline demographics and remove any participants who do not meet the stated inclusion criteria.

```{r mci_baseline}
# load the dataset
mci_baseline_df = 
  read_csv("./data/data_mci/MCI_baseline.csv", 
           skip = 1) |>
  
#clean data
  janitor::clean_names() |> 
  
#encode sex and APOE4 carrier status
  mutate(
    sex = ifelse(sex == 1, "male", "female"),
    apoe4 = ifelse(apoe4 == 1, "carrier", "non-carrier" )
         ) 
mci_baseline_df

# remove the participants who don't meet the stated inclusion criteria
mci_at_baseline_df = mci_baseline_df |>
  mutate(age_at_onset = ifelse(age_at_onset == '.', NA, age_at_onset)) |> 
  filter(current_age < age_at_onset | is.na(age_at_onset))

mci_at_baseline_df


# calculate for the average baseline age
base_mean_age_mci = mean(pull(mci_at_baseline_df, current_age))

#calculate the proportion
n_carrier_female = mci_at_baseline_df |> 
  filter(sex == 'female') |> 
  filter(apoe4 == 'carrier') |> 
  count()

n_female = mci_baseline_df |> 
  filter(sex == 'female') |> 
  count()

proportion = n_carrier_female/n_female
```

The first row must be skipped throughout the import procedure because our dataset does not require remarks.Based on notes, Sex == 0 represents the participant is female. apoe4 == 0 represents the participant is non-carrier. Then we use mutate funtion to ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric) according to notes. We also use filter function to remove any participants who do not meet the stated inclusion criteria. It means you need to remove any N/A value in variable `age at onset` variable by using filter function. There are `r nrow(mci_baseline_df)` participants were recruited, `r nrow(mci_at_baseline_df)` develop MCI. The average baseline age is `r base_mean_age_mci`. The proportion of women in the study are APOE4 carriers is `r proportion`.


First, Import, clean, and tidy the dataset of longitudinally observed biomarker values.

```{r}
# load the amyloid dataset
mci_amyloid_df = read.csv('./data/data_mci/mci_amyloid.csv', skip = 1) |> 
  janitor::clean_names()

mci_amyloid_df = mci_amyloid_df |> 
  rename(id = study_id,
         second_year = time_2,
         fourth_year = time_4,
         sixth_year = time_6,
         eighth_year = time_8) |> 
  pivot_longer(
    baseline:eighth_year,
    names_to = "time",
    values_to = "value"
    )

```
We still don't require notes in this dataset, so we skip the first row. The study_id and time variables are changed to id and years. To make the dataset easier to understand by clearly displaying time and value, we use pivot_longer() function. The dateset has some NA values, which indicates that certain ratio values are missing. There are `r nrow(mci_amyloid_df)` observations and `r ncol(mci_amyloid_df)` variables. The dateframe contains important variables like id, year, and value once the dataset has been cleaned and organized. 

Second, check whether some participants appear in only the baseline or amyloid datasets and combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained.

```{r}
#Check participants appearing in only baseline or amyloid datasets
unique_baseline_participants = anti_join(mci_at_baseline_df, mci_amyloid_df,by = "id")

unique_amyloid_participants = anti_join(mci_amyloid_df, mci_at_baseline_df, by = "id")

only_baseline_id = mci_at_baseline_df |> 
  pull(id) |> 
  setdiff(mci_amyloid_df |> pull(id))

only_amyloid_id = mci_amyloid_df |> 
  pull(id) |> 
  setdiff(mci_at_baseline_df |> pull(id))

# combine two datasets together
combined_dataframe = inner_join(mci_at_baseline_df, mci_amyloid_df, by = "id")
```
Only participants with the id `r only_baseline_id` exist in the baseline dataset, totaling `r nrow(unique_baseline_participants)`.Only participants with the id `r only_amyloid_id` present in the amyloid dataset, totaling `r nrow(unique_amyloid_participants)/5`. 
There are `r nrow(combined_dataframe)/5` participants present in both datasets; each participant has 5 rows of data (baseline to 8th year), hence there are `r nrow(combined_dataframe)` rows total in the combined dataset. The variables are `r ncol(combined_dataframe)`. 

```{r}
# export the result as a CSV to your data directory
write.csv(combined_dataframe, file = "./data/data_mci/combined_dataframe.csv", row.names = T)
```

